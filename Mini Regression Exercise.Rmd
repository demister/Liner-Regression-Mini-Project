---
title: "Mini Regression Exercise"
author: "Dee Muralidharan"
date: "August 4, 2017"
output: html_document
---


## Exercise: least squares regression
## ────────────────────────────────────────

```{r}
getwd() # where am I?
setwd ("D:/springboard Data science/Exercises/Machine Learning")
##list.files("D:/springboard Data science/Exercises/Machine Learning")
states.data <- readRDS("states.rds") 
states.info <- data.frame(attributes(states.data)[c("names", "var.labels")])
write.csv(states.data, "states.csv" )
tail(states.info, 8)
```

##   Use the /states.rds/ data set. Fit a model predicting energy consumed
##   per capita (energy) from the percentage of residents living in
##   metropolitan areas (metro). Be sure to
1. Examine/plot the data before fitting the model
```{r}
# summary of expense and csat columns, all rows

sts.ex.sat <- subset(states.data, select = c("energy", "metro"))
summary(sts.ex.sat)

## Plot energy and metro
plot(states.data$energy,states.data$metro)

# correlation between expense and csat

cor(na.omit(sts.ex.sat))

# There seems to be a possible negative correlation between energy consumed 
#and residents living in a metro area.
```

2. Print and interpret the model `summary'

```{r}

# Fit our regression model
sat.mod <- lm(energy ~ metro, # regression formula
              data=states.data) # data set
# Summarize and print the results
summary(sat.mod) # show regression coefficients table
plot(sat.mod)
cor(na.omit (stat.mod))
```

It can be inferred that the correlation is very poor as the Adjusted R-squared:  0.097. The contribution of metro potulation to the liner model of energy use is very poor.

Will Try to find the best corellation that would benefit the energy usage column
```{r}
## Tidy data from the file 1. Remove rows with na's. 2.Remove state and regions
##install.packages("dplyr")
library(dplyr)
##install.packages("tidyr")
library(tidyr)
states.data1 <- states.data %>% drop_na(pop)
states.data1 <- states.data %>% drop_na(green)
states.data1 <- states.data1 %>% select(-state, -region)
write.csv(states.data1, "D:/springboard Data science/Exercises/Machine Learning/states.csv" )
cor(states.data1)
```

It can be found using the corr function that state "area", "toxic" , "Green" and "house" have the best corellations and hence are co-leniar

              energy      
pop       -0.184035749 
area    ##0.662651876
density   -0.328420337 
metro     -0.339744521 
waste     -0.252649916 
energy    1.000000000  
miles     0.233889397  
toxic   ##0.562452402  
green  ##0.7706181        
house  ##-0.634687245 
senate  -0.477318891 
csat     0.164901350  
vsat     0.187582680  
msat     0.141883149 
percent -0.304003280 
expense -0.006950791 
income  -0.143685178 
high     0.039718282 
college -0.224146236 

 Lets try and create a regression model using these values and study the best fit and the r2 values
 
```{r}
stat.mod.energy <-  lm(energy ~ pop + area+ +density +metro + waste + miles + toxic + green + house + expense + income, # regression formula
              data=states.data1)
summary(stat.mod.energy)
plot(stat.mod.energy)
```
```{r}
stat.mod.energy2 <-  lm(energy ~   area+ + toxic + green  , # regression formula
              data=states.data1)
summary(stat.mod.energy2)
plot(stat.mod.energy2)
```



This model (stat.mod.energy2) has a better Adjusted r2 value (0.7652) compared to the previous models (stat.mod.energy) adjusted r2 value of 0.7356, hence is a better fit. It was also found that omitting house all the irrevelant values increase the r2 value.  

## Interactions and factors
## ══════════════════════════

## Modeling interactions
## ─────────────────────────

##   Interactions allow us assess the extent to which the association
##   between one predictor and the outcome depends on a second predictor.
##   For example: Does the association between expense and SAT scores
##   depend on the median income in the state?
 

## Modeling interactions

## ─────────────────────────

##   Interactions allow us assess the extent to which the association
##   between one predictor and the outcome depends on a second predictor.
##   For example: Does the association between expense and SAT scores
##   depend on the median income in the state?

  #Add the interaction to the model
  
##   1. Add on to the regression equation that you created in exercise 1 by

##      generating an interaction term and testing the interaction

```{r}
  #Add the interaction to the model
 
energy.inter <- lm(energy ~ toxic * green, data = states.data1)
#Show the results
  coef(summary(energy.inter)) # show regression coefficients table
  summary(energy.inter)
```
##   2. Try adding region to the model. Are there significant differences
##      across the four regions?

```{r}

# Generate and test this regression again with region in the model
model.states.intra <- lm(energy ~ green * toxic + region, data =  na.omit(states.data))
# make sure R knows region is categorical
str(states.data$region)
states.data$region <- factor(states.data$region)
#Add region to the model
sat.region <- lm(energy ~ region, data=states.data)
summary(sat.region)
```

 
##There does appear to be differences between regions.  It seems the South is correlatedwith higher energy use while the Northeast and Midwest are negatively correlated with energy use. The addition of region increased the R squared on the model even further.
 
 
```{r}
model.ex2 <- lm(energy ~ metro*green + region, data = na.omit(states.data))
summary(model.ex2)

```
